import csv
import zipfile
import os
import re
import chardet
import requests
import json
import base64
import hashlib
from datetime import datetime, timedelta
import schedule
import time
import logging
from report_generator import ReportGenerator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log', encoding='utf-8')
    ]
)

class CallRecordingReporter:
    def __init__(self, webhook_url, file_dir='file'):
        self.webhook_url = webhook_url
        self.file_dir = file_dir
        self.processed_files = set()
        self.team_mapping = {}
        self.load_team_mapping()
        
    def load_team_mapping(self):
        """åŠ è½½å›¢é˜Ÿæ˜ å°„æ–‡ä»¶"""
        try:
            mapping_file = os.path.join(self.file_dir, 'team_mapping.csv')
            if not os.path.exists(mapping_file):
                logging.warning(f"å›¢é˜Ÿæ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
                return
                
            with open(mapping_file, 'rb') as f:
                raw_data = f.read()
                encoding_result = chardet.detect(raw_data)
                encoding = encoding_result['encoding'] or 'gbk'
                
            with open(mapping_file, 'r', encoding=encoding) as csvfile:
                reader = csv.reader(csvfile)
                next(reader, None)  # è·³è¿‡æ ‡é¢˜è¡Œ
                for row in reader:
                    if len(row) >= 2:
                        team_name, account_id = row[0].strip(), row[1].strip()
                        self.team_mapping[account_id] = team_name
                        
            logging.info(f"å·²åŠ è½½ {len(self.team_mapping)} ä¸ªå›¢é˜Ÿæ˜ å°„")
            
        except Exception as e:
            logging.error(f"åŠ è½½å›¢é˜Ÿæ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            
    def get_today_files(self):
        """è·å–ä»Šå¤©çš„æ–°zipæ–‡ä»¶"""
        today = datetime.now().strftime('%Y%m%d')
        today_files = []
        
        if not os.path.exists(self.file_dir):
            os.makedirs(self.file_dir)
            return today_files
            
        for filename in os.listdir(self.file_dir):
            if filename.endswith('.zip') and today in filename:
                if filename not in self.processed_files:
                    today_files.append(filename)
                    
        return today_files
        
    def extract_date_from_filename(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ"""
        # åŒ¹é…æ–‡ä»¶åä¸­çš„æ—¥æœŸæ ¼å¼ï¼Œå¦‚ 20251114155531338
        date_pattern = r'(\d{8})\d{6}'
        match = re.search(date_pattern, filename)
        if match:
            date_str = match.group(1)
            return datetime.strptime(date_str, '%Y%m%d').date()
        return None
        
    def process_zip_file(self, zip_filename):
        """å¤„ç†å•ä¸ªzipæ–‡ä»¶"""
        try:
            zip_path = os.path.join(self.file_dir, zip_filename)
            logging.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {zip_filename}")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # è·å–zipä¸­çš„csvæ–‡ä»¶
                csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                if not csv_files:
                    logging.warning(f"zipæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°csvæ–‡ä»¶: {zip_filename}")
                    return None
                    
                csv_filename = csv_files[0]
                
                # è¯»å–csvæ–‡ä»¶å†…å®¹
                with zip_ref.open(csv_filename, 'r') as csvfile:
                    raw_data = csvfile.read()
                    
                    # æ£€æµ‹ç¼–ç 
                    encoding_result = chardet.detect(raw_data)
                    encoding = encoding_result['encoding'] or 'gbk'
                    logging.info(f"æ£€æµ‹åˆ°ç¼–ç : {encoding}")
                    
                    # å°è¯•å¤šç§ç¼–ç è§£ç 
                    content = None
                    encodings_to_try = [encoding, 'gbk', 'utf-8', 'gb2312', 'big5']
                    
                    for enc in encodings_to_try:
                        try:
                            content = raw_data.decode(enc)
                            logging.info(f"æˆåŠŸä½¿ç”¨ç¼–ç : {enc}")
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if content is None:
                        content = raw_data.decode('gbk', errors='ignore')
                        logging.warning("ä½¿ç”¨å¿½ç•¥é”™è¯¯çš„æ–¹å¼è§£ç ")
                    lines = content.splitlines()
                    
                    # è§£æCSVæ•°æ®
                    reader = csv.reader(lines)
                    header = next(reader, None)
                    if not header:
                        logging.warning(f"CSVæ–‡ä»¶æ²¡æœ‰æ ‡é¢˜è¡Œ: {csv_filename}")
                        return None
                        
                    logging.info(f"CSVæ ‡é¢˜: {header}")
                    
                    # ç»Ÿè®¡æ•°æ®
                    report_data = {}
                    total_operations = 0
                    
                    for row_num, row in enumerate(reader, start=2):  # ä»ç¬¬2è¡Œå¼€å§‹è®¡æ•°
                        try:
                            if len(row) < 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                                continue
                                
                            account = row[1].strip()  # å¸å·åœ¨ç¬¬2åˆ—
                            name = row[2].strip()     # å§“ååœ¨ç¬¬3åˆ—
                            operation_time = row[5].strip()  # æ“ä½œæ—¶é—´åœ¨ç¬¬6åˆ—
                            
                            # è·³è¿‡ç©ºè¡Œ
                            if not account or not name:
                                continue
                                
                            logging.debug(f"å¤„ç†æ•°æ®: è´¦å·={account}, å§“å={name}, æ—¶é—´={operation_time}")
                            
                            # å¦‚æœè´¦å·åœ¨å›¢é˜Ÿæ˜ å°„ä¸­ï¼Œåˆ™ç»Ÿè®¡
                            if account in self.team_mapping:
                                team = self.team_mapping[account]
                                key = (team, name, account)
                                if key not in report_data:
                                    report_data[key] = 0
                                report_data[key] += 1
                                total_operations += 1
                                
                        except Exception as e:
                            logging.warning(f"è·³è¿‡ç¬¬{row_num}è¡Œæ•°æ®: {e}, è¡Œå†…å®¹: {row}")
                            continue
                            
                    # ç”ŸæˆæŠ¥è¡¨
                    report_date = self.extract_date_from_filename(zip_filename)
                    return ReportGenerator.generate_report(report_data, report_date, total_operations, zip_filename, self.file_dir, 'both')
                    
        except Exception as e:
            logging.error(f"å¤„ç†æ–‡ä»¶ {zip_filename} æ—¶å‡ºé”™: {e}")
            return None
            
        
    def _calculate_md5(self, data):
        """è®¡ç®—æ•°æ®çš„MD5å€¼"""
        return hashlib.md5(data).hexdigest()
    
    def _image_to_base64(self, image_path):
        """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            # æ£€æŸ¥å›¾ç‰‡å¤§å°ï¼ˆä¸èƒ½è¶…è¿‡2Mï¼‰
            if len(image_data) > 2 * 1024 * 1024:
                logging.error(f"å›¾ç‰‡å¤§å°è¶…è¿‡2Mé™åˆ¶: {len(image_data)} bytes")
                return None, None
            
            # è®¡ç®—MD5
            md5_hash = self._calculate_md5(image_data)
            
            # è½¬æ¢ä¸ºbase64
            base64_data = base64.b64encode(image_data).decode('utf-8')
            
            return base64_data, md5_hash
        except Exception as e:
            logging.error(f"å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
            return None, None
        
    def send_to_wechat(self, report_data):
        """å‘é€æŠ¥è¡¨åˆ°ä¼ä¸šå¾®ä¿¡ç¾¤"""
        if not report_data:
            logging.warning("æ²¡æœ‰æŠ¥è¡¨æ•°æ®å¯å‘é€")
            return False
            
        try:
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logging.info(f"å‡†å¤‡å‘é€æŠ¥è¡¨æ•°æ®: {report_data.keys()}")
            logging.info(f"æ–‡æœ¬å†…å®¹é¢„è§ˆ: {report_data['text'][:200]}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æŠ¥è¡¨
            if 'image_filename' in report_data:
                logging.info("æ£€æµ‹åˆ°å›¾ç‰‡æŠ¥è¡¨ï¼Œå‡†å¤‡å‘é€ç»„åˆæ¶ˆæ¯")
                image_path = os.path.join(self.file_dir, report_data['image_filename'])
                # å°è¯•ä½¿ç”¨JPEGæ ¼å¼çš„å›¾ç‰‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                jpeg_path = image_path[:-4] + '.jpg' if image_path.endswith('.png') else image_path
                
                # ä¼˜å…ˆä½¿ç”¨JPEGæ ¼å¼
                if os.path.exists(jpeg_path):
                    image_path = jpeg_path
                    logging.info(f"ä½¿ç”¨JPEGæ ¼å¼å›¾ç‰‡: {image_path}")
                elif not os.path.exists(image_path):
                    # å¦‚æœå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å›¾ç‰‡å‘é€
                    logging.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                else:
                    # ä½¿ç”¨PNGæ ¼å¼
                    logging.info(f"ä½¿ç”¨PNGæ ¼å¼å›¾ç‰‡: {image_path}")
                
                if os.path.exists(image_path):
                    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
                    file_extension = os.path.splitext(image_path)[1].lower()
                    if file_extension not in ['.jpg', '.jpeg', '.png']:
                        logging.error(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {file_extension}")
                    else:
                        # è½¬æ¢å›¾ç‰‡ä¸ºbase64å’Œmd5
                        base64_data, md5_hash = self._image_to_base64(image_path)
                        
                        if base64_data and md5_hash:
                            # åˆ›å»ºmarkdownæ ¼å¼çš„æ¶ˆæ¯ï¼ŒåŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡
                            # æ³¨æ„ï¼šä¼ä¸šå¾®ä¿¡markdownæ¶ˆæ¯ä¸æ”¯æŒç›´æ¥åµŒå…¥å›¾ç‰‡ï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆå‘é€å›¾ç‰‡ï¼Œå†å‘é€markdownæ–‡æœ¬
                            # ä½†æˆ‘ä»¬å¯ä»¥ä¼˜åŒ–æ¶ˆæ¯æ ¼å¼ï¼Œè®©æ–‡æœ¬æ›´æ¸…æ™°
                            
                            logging.info("å‘é€å›¾ç‰‡æ¶ˆæ¯...")
                            image_message = {
                                "msgtype": "image",
                                "image": {
                                    "base64": base64_data,
                                    "md5": md5_hash
                                }
                            }
                            
                            response = requests.post(
                                self.webhook_url,
                                json=image_message,
                                timeout=10
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                if result.get('errcode') == 0:
                                    logging.info("å›¾ç‰‡æŠ¥è¡¨å‘é€æˆåŠŸ")
                                    
                                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿å›¾ç‰‡æ¶ˆæ¯æ˜¾ç¤º
                                    import time
                                    time.sleep(0.5)
                                    
                                    # å‘é€markdownæ ¼å¼çš„æ–‡æœ¬æ¶ˆæ¯
                                    markdown_content = report_data['text']
                                    
                                    # ä¼˜åŒ–æ–‡æœ¬æ ¼å¼ï¼Œæ·»åŠ è¯´æ˜
                                    if not markdown_content.startswith("ğŸ“Š å¬å½•éŸ³ç»Ÿè®¡æŠ¥è¡¨"):
                                        markdown_content = f"ğŸ“Š å¬å½•éŸ³ç»Ÿè®¡æŠ¥è¡¨\n{markdown_content}"
                                    
                                    markdown_message = {
                                        "msgtype": "markdown",
                                        "markdown": {
                                            "content": markdown_content
                                        }
                                    }
                                    
                                    logging.info("å‘é€markdownæ–‡æœ¬æ¶ˆæ¯...")
                                    response = requests.post(
                                        self.webhook_url,
                                        json=markdown_message,
                                        timeout=10
                                    )
                                    
                                    if response.status_code == 200:
                                        result = response.json()
                                        if result.get('errcode') == 0:
                                            logging.info("markdownæ–‡æœ¬æŠ¥è¡¨å‘é€æˆåŠŸ")
                                            return True
                                        else:
                                            logging.error(f"markdownæ–‡æœ¬å‘é€å¤±è´¥: {result}")
                                            return False
                                    else:
                                        logging.error(f"markdownæ–‡æœ¬HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                                        return False
                                else:
                                    logging.error(f"å›¾ç‰‡å‘é€å¤±è´¥: {result}")
                                    # å¦‚æœå›¾ç‰‡å‘é€å¤±è´¥ï¼Œå°è¯•å‘é€markdownæ–‡æœ¬
                                    return self._send_markdown_text_only(report_data['text'])
                            else:
                                logging.error(f"å›¾ç‰‡HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                                # å¦‚æœå›¾ç‰‡å‘é€å¤±è´¥ï¼Œå°è¯•å‘é€markdownæ–‡æœ¬
                                return self._send_markdown_text_only(report_data['text'])
                        else:
                            logging.error("å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œæ— æ³•è·å–base64æˆ–md5")
                            # å¦‚æœå›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œå°è¯•å‘é€markdownæ–‡æœ¬
                            return self._send_markdown_text_only(report_data['text'])
                else:
                    # å¦‚æœæ²¡æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œåªå‘é€markdownæ–‡æœ¬
                    return self._send_markdown_text_only(report_data['text'])
            else:
                # å¦‚æœæ²¡æœ‰å›¾ç‰‡æŠ¥è¡¨ï¼Œåªå‘é€markdownæ–‡æœ¬
                return self._send_markdown_text_only(report_data['text'])
                
        except Exception as e:
            logging.error(f"å‘é€æŠ¥è¡¨æ—¶å‡ºé”™: {e}")
            return False
    
    def _send_markdown_text_only(self, text_content):
        """åªå‘é€markdownæ ¼å¼çš„æ–‡æœ¬æ¶ˆæ¯"""
        try:
            markdown_message = {
                "msgtype": "markdown",
                "markdown": {
                    "content": text_content
                }
            }
            
            logging.info("å‘é€çº¯markdownæ–‡æœ¬æ¶ˆæ¯...")
            response = requests.post(
                self.webhook_url,
                json=markdown_message,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logging.info("çº¯markdownæ–‡æœ¬æŠ¥è¡¨å‘é€æˆåŠŸ")
                    return True
                else:
                    logging.error(f"çº¯markdownæ–‡æœ¬å‘é€å¤±è´¥: {result}")
                    return False
            else:
                logging.error(f"çº¯markdownæ–‡æœ¬HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            logging.error(f"å‘é€çº¯markdownæ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return False
            
    def process_daily_files(self):
        """å¤„ç†å½“å¤©çš„æ–°æ–‡ä»¶"""
        logging.info("å¼€å§‹æ£€æŸ¥å½“å¤©çš„æ–°æ–‡ä»¶...")
        
        today_files = self.get_today_files()
        if not today_files:
            logging.info("æ²¡æœ‰æ‰¾åˆ°å½“å¤©çš„æ–°æ–‡ä»¶")
            return
            
        logging.info(f"æ‰¾åˆ° {len(today_files)} ä¸ªå½“å¤©çš„æ–°æ–‡ä»¶: {today_files}")
        
        for filename in today_files:
            try:
                report_data = self.process_zip_file(filename)
                if report_data:
                    # å‘é€åˆ°ä¼ä¸šå¾®ä¿¡
                    if self.send_to_wechat(report_data):
                        logging.info(f"æ–‡ä»¶ {filename} å¤„ç†å®Œæˆå¹¶å‘é€æˆåŠŸ")
                    else:
                        logging.error(f"æ–‡ä»¶ {filename} å‘é€å¤±è´¥")
                        
                # æ ‡è®°ä¸ºå·²å¤„ç†
                self.processed_files.add(filename)
                
            except Exception as e:
                logging.error(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                
    def run_scheduler(self):
        """è¿è¡Œå®šæ—¶ä»»åŠ¡"""
        logging.info("å¯åŠ¨å®šæ—¶ä»»åŠ¡...")
        
        # æ¯å¤©ä¸Šåˆ9ç‚¹æ‰§è¡Œ
        schedule.every().day.at("09:00").do(self.process_daily_files)
        
        # ä¹Ÿå¯ä»¥æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡æ–°æ–‡ä»¶
        schedule.every().hour.do(self.process_daily_files)
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            
    def run_once(self):
        """ç«‹å³æ‰§è¡Œä¸€æ¬¡å¤„ç†"""
        self.process_daily_files()

def main():
    # ä¼ä¸šå¾®ä¿¡æœºå™¨äººwebhook
    webhook_url = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=2645bd5f-4802-45dc-8fd7-c46f67d317a9"
    
    # åˆ›å»ºæŠ¥è¡¨å¤„ç†å™¨
    reporter = CallRecordingReporter(webhook_url)
    
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == '--schedule':
        # å®šæ—¶è¿è¡Œæ¨¡å¼
        reporter.run_scheduler()
    else:
        # ç«‹å³è¿è¡Œæ¨¡å¼
        reporter.run_once()

if __name__ == "__main__":
    main()